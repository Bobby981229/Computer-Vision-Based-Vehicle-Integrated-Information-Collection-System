import os
import cv2
import numpy as np
from tensorflow import keras


def unet_predict(unet, img_src_path):
    img_src = cv2.imdecode(np.fromfile(
        img_src_path, dtype=np.uint8), -1)  # 从中文路径读取时用
    # img_src=cv2.imread(img_src_path)
    if img_src.shape != (512, 512, 3):
        # dsize=(宽度,高度),[:,:,:3]是防止图片为4通道图片，后续无法reshape
        img_src = cv2.resize(img_src, dsize=(512, 512))[:, :, :3]
    img_src = img_src.reshape(1, 512, 512, 3)  # 预测图片shape为(1,512,512,3)
    img_mask = unet.predict(img_src)  # 归一化除以255后进行预测

    img_src = img_src.reshape(512, 512, 3)  # 将原图reshape为3维
    img_mask = img_mask.reshape(512, 512, 3)  # 将预测后图片reshape为3维

    img_mask = img_mask / np.max(img_mask) * 255  # 归一化后乘以255
    img_mask[:, :, 2] = img_mask[:, :, 1] = img_mask[:, :, 0]  # 三个通道保持相同
    img_mask = img_mask.astype(np.uint8)  # 将img_mask类型转为int型

    return img_src, img_mask


def locate(img_src, img_mask, name):
    """
    该函数通过cv2对img_mask进行边缘检测，获取车牌区域的边缘坐标(存储在contours中)和最小外接矩形4个端点坐标,
    再从车牌的边缘坐标中计算出和最小外接矩形4个端点最近的点即为平行四边形车牌的四个端点,从而实现车牌的定位和矫正
    :param img_src: 原始图片
    :param img_mask: 通过u_net预测得到的二值化图片，车牌区域呈现白色，背景区域为黑色
    :return: 定位且矫正后的车牌
    """
    contours, hierarchy = cv2.findContours(
        img_mask[:, :, 0], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not len(contours):  # contours1长度为0说明未检测到车牌
        print("未检测到车牌")
    else:
        flag = 0  # 默认flag为0，因为不一定有车牌区域
        for i, cont in enumerate(contours):
            x, y, w, h = cv2.boundingRect(cont)  # 获取最小外接矩形
            img_cut_mask = img_mask[y:y + h, x:x + w]  # 将标签车牌区域截取出来
            if np.mean(img_cut_mask) >= 75 and w > 15 and h > 15:
                # 针对坐标点获取带方向角的最小外接矩形，中心点坐标，宽高，旋转角度
                rect = cv2.minAreaRect(cont)
                box = cv2.boxPoints(rect).astype(np.int32)  # 获取最小外接矩形四个顶点坐标
                cv2.drawContours(img_mask, contours, -1, (0, 0, 255), 2)
                cv2.drawContours(img_mask, [box], 0, (0, 255, 0), 2)

                cont = cont.reshape(-1, 2).tolist()
                # 由于转换矩阵的两组坐标位置需要一一对应，因此需要将最小外接矩形的坐标进行排序，最终排序为[左上，左下，右上，右下]
                # 先按照左右进行排序，分为左侧的坐标和右侧的坐标
                box = sorted(box, key=lambda xy: xy[0])
                # 此时box的前2个是左侧的坐标，后2个是右侧的坐标
                box_left, box_right = box[:2], box[2:]
                # 再按照上下即y进行排序，此时box_left中为左上和左下两个端点坐标
                box_left = sorted(box_left, key=lambda x: x[1])
                # 此时box_right中为右上和右下两个端点坐标
                box_right = sorted(box_right, key=lambda x: x[1])
                box = np.array(box_left + box_right)  # [左上，左下，右上，右下]

                # 这里的4个坐标即为最小外接矩形的四个坐标，接下来需获取平行(或不规则)四边形的坐标
                x0, y0 = box[0][0], box[0][1]
                x1, y1 = box[1][0], box[1][1]
                x2, y2 = box[2][0], box[2][1]
                x3, y3 = box[3][0], box[3][1]

                def point_to_line_distance(X, Y):
                    if x2 - x0:
                        k_up = (y2 - y0) / (x2 - x0)  # 斜率不为无穷大
                        d_up = abs(k_up * X - Y + y2 - k_up * x2) / \
                            (k_up ** 2 + 1) ** 0.5
                    else:  # 斜率无穷大
                        d_up = abs(X - x2)
                    if x1 - x3:
                        k_down = (y1 - y3) / (x1 - x3)  # 斜率不为无穷大
                        d_down = abs(k_down * X - Y + y1 - k_down *
                                     x1) / (k_down ** 2 + 1) ** 0.5
                    else:  # 斜率无穷大
                        d_down = abs(X - x1)
                    return d_up, d_down

                d0, d1, d2, d3 = np.inf, np.inf, np.inf, np.inf
                l0, l1, l2, l3 = (x0, y0), (x1, y1), (x2, y2), (x3, y3)
                for each in cont:  # 计算cont中的坐标与矩形四个坐标的距离以及到上下两条直线的距离，对距离和进行权重的添加，成功选出四边形的4个顶点坐标
                    x, y = each[0], each[1]
                    dis0 = (x - x0) ** 2 + (y - y0) ** 2
                    dis1 = (x - x1) ** 2 + (y - y1) ** 2
                    dis2 = (x - x2) ** 2 + (y - y2) ** 2
                    dis3 = (x - x3) ** 2 + (y - y3) ** 2
                    d_up, d_down = point_to_line_distance(x, y)
                    weight = 0.975
                    if weight * d_up + (1 - weight) * dis0 < d0:
                        d0 = weight * d_up + (1 - weight) * dis0
                        l0 = (x, y)
                    if weight * d_down + (1 - weight) * dis1 < d1:
                        d1 = weight * d_down + (1 - weight) * dis1
                        l1 = (x, y)
                    if weight * d_up + (1 - weight) * dis2 < d2:
                        d2 = weight * d_up + (1 - weight) * dis2
                        l2 = (x, y)
                    if weight * d_down + (1 - weight) * dis3 < d3:
                        d3 = weight * d_down + (1 - weight) * dis3
                        l3 = (x, y)

                # 左上角，左下角，右上角，右下角，形成的新box顺序需和原box中的顺序对应，以进行转换矩阵的形成
                p0 = np.float32([l0, l1, l2, l3])
                p1 = np.float32([(0, 0), (0, 80), (240, 0), (240, 80)])
                transform_mat = cv2.getPerspectiveTransform(p0, p1)  # 构成转换矩阵
                lic = cv2.warpPerspective(
                    img_src, transform_mat, (240, 80))  # 进行车牌矫正

                if len(contours) == 1:  # 只有一个区域可以认为是车牌区域
                    flag += 1
                    print('saving ', save_path + name[0:7] + '.jpg')
                    cv2.imencode('.jpg', lic)[1].tofile(
                        save_path + name[0:7] + '.jpg')

        if not flag:
            print("未检测到车牌区域或车牌区域过小")


if __name__ == '__main__':
    test_path = '../labelme/labeled_img/'  # 利用百度API标注或手动标注好的图片
    save_path = '../labelme/license_img/'  # 车牌图片保存路径
    unet_path = 'unet_green10.h5'
    listdir = os.listdir(test_path)
    unet = keras.models.load_model(unet_path)
    # print(listdir)
    for name in listdir:
        print(name)
        img_src_path = test_path + name
        img_src, img_mask = unet_predict(unet, img_src_path)
        locate(img_src, img_mask, name)
